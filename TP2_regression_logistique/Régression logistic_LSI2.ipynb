{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpG7Nd4v9Xca"
   },
   "source": [
    "# To predict heart disease\n",
    "In this Lab, we ask you to apply the Logistic Regression to predict heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzbOp32s9Xcf"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "* **Sex**: male or female(Nominal)\n",
    "* **Age**: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "* **Current Smoker**: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.) or not the patient is a current smoker (Nominal)\n",
    "* **Cigs Per Day**: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "* **BP Meds**: whether or not the patient was on blood pressure medication (Nominal)\n",
    "* **Prevalent Stroke**: whether or not the patient had previously had a stroke (Nominal)\n",
    "* **Prevalent Hyp**: whether or not the patient was hypertensive (Nominal)\n",
    "* **Diabetes**: whether or not the patient had diabetes (Nominal)\n",
    "* **Tot Chol**: total cholesterol level (Continuous)\n",
    "* **Sys BP**: systolic blood pressure (Continuous)\n",
    "* **Dia BP**: diastolic blood pressure (Continuous)\n",
    "* **BMI** Body Mass Index (Continuous)\n",
    "* **Heart Rate**: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "* **Glucose**: glucose level (Continuous)\n",
    "\n",
    "```Predict variable (desired target```\n",
    "\n",
    "**10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p4ZCTpyI9Xch"
   },
   "outputs": [],
   "source": [
    "# imports you libraries\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Kn5vXEB9Xcj"
   },
   "outputs": [],
   "source": [
    "heart_disease = # your code here\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5R3HTRZ29Xck"
   },
   "outputs": [],
   "source": [
    "# print some info about the dataframe\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaeMDHTJ9Xck"
   },
   "source": [
    "Looks like there are some Nan values, let's see how many for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5AI_2olL9Xck"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsjzeWQA9Xcl"
   },
   "source": [
    "Replace the Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fg6Yzqkc9Xcm"
   },
   "outputs": [],
   "source": [
    "# check the fillna documentation: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lO-sbAc9Xcn"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPZdkF3K9Xcn"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print ('heart disease rate =', heart_disease.TenYearCHD.mean())\n",
    "(heart_disease.groupby('TenYearCHD').size()/heart_disease.shape[0]).plot(kind=\"bar\",title=\"Label's Balance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mVjSojhJ9Xco"
   },
   "outputs": [],
   "source": [
    "# make a function to plot survival against passenger attribute\n",
    "def heart_disease_rate(column,t):\n",
    "    df=pd.DataFrame()\n",
    "    df['total']=heart_disease.groupby(column).size()\n",
    "    df['TenYearCHD'] = heart_disease.groupby(column).sum()['TenYearCHD']\n",
    "    df['percentage'] = round(df['TenYearCHD']/df['total']*100,2)\n",
    "    print(df)\n",
    "\n",
    "    df['TenYearCHD'].plot(kind=t)\n",
    "    df['total'].plot(kind=t,alpha=0.5,title=\"TenYearCHD per \"+str(column))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e9Ds55q79Xco"
   },
   "outputs": [],
   "source": [
    "# Draw survival per Sex\n",
    "heart_disease_rate(\"male\",\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ESv52uFP9Xcp"
   },
   "outputs": [],
   "source": [
    "# Draw survival per cigard per day consomation\n",
    "heart_disease_rate(\"cigsPerDay\",\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YrTGe5Yw9Xcp"
   },
   "outputs": [],
   "source": [
    "# Graph survived per current Smoker\n",
    "heart_disease_rate(\"currentSmoker\",\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HMoRYtzq9Xcp"
   },
   "outputs": [],
   "source": [
    "# Draw survived per Number of diabetes\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "FN4wuUhv9Xcp"
   },
   "outputs": [],
   "source": [
    "# Draw survived per Number of hypertensive\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fEc4HUu9Xcq"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZFt_bUDH9Xcq"
   },
   "outputs": [],
   "source": [
    "#Put only important columns in predictors. You have to find if there is column to remove\n",
    "predictors = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7CvWSj-k9Xcr"
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a testing set. Set: test_size=0.3, random_state=1\n",
    "# your code here\n",
    "\n",
    "print (\"train shape\", X_train.shape, y_train.shape)\n",
    "print (\"test shape\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "KBjnYcSk9Xcr"
   },
   "outputs": [],
   "source": [
    "# import LogisticRegression from: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# your code here\n",
    "clf = LogisticRegression(random_state=1)\n",
    "# your code here\n",
    "train_score = # your code here\n",
    "test_score = # your code here\n",
    "print ('train accuracy =', train_score)\n",
    "print ('test accuracy =', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h_lLo9L9Xcs"
   },
   "source": [
    "Let's print the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "g8O0eXo-9Xcs"
   },
   "outputs": [],
   "source": [
    "coeff = pd.DataFrame()\n",
    "coeff['Feature'] = X_train.columns\n",
    "coeff['Coefficient Estimate'] = pd.Series(clf.coef_[0])\n",
    "coeff.loc[len(coeff)]=['Intercept',clf.intercept_[0]]\n",
    "print (coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqGOuOla9Xcs"
   },
   "source": [
    "We now need to predict class labels for the test set. We will also generate the class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "XP9i5RY89Xcs"
   },
   "outputs": [],
   "source": [
    "# predict class labels for the test set\n",
    "y_pred = # your code here\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "YcyX1vod9Xcs"
   },
   "outputs": [],
   "source": [
    "# generate class probabilities : http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "y_probs = # your code here\n",
    "print (y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZcfyRhp9Xcs"
   },
   "source": [
    "As you can see, the classifier outputs two probabilities for each row. It's predicting a 1 any time the probability in the second column is greater than 0.5. Let's visualize it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "NpLKax-J9Xcs"
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame({        \n",
    "        \"Heart_disease_original\": y_test,\n",
    "        \"Heart_disease_predicted\": y_pred,\n",
    "        \"Heart_disease_proba\": np.transpose(y_probs)[1]      \n",
    "        })\n",
    "pred[\"Comparison\"]= pred.Heart_disease_original ==pred.Heart_disease_predicted\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Phow9sQf9Xct"
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5uI53Euc9Xct"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (metrics.confusion_matrix(y_test, y_pred))\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uvm8Z-pM9Xct"
   },
   "source": [
    "As you can see, we can have the classification report for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOBU4czd9Xct"
   },
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vY5Jyd6E9Xct"
   },
   "outputs": [],
   "source": [
    "# import cross_validation from: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "# your code here\n",
    "clf = LogisticRegression(random_state=1)\n",
    "scores = cross_validation.cross_val_score(clf, heart_disease[predictors], heart_disease[\"TenYearCHD\"], scoring='accuracy', cv=5)\n",
    "## see model \n",
    "print(scores)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "wzBrwUE_9Xct"
   },
   "source": [
    "When you are improving a model, you want to make sur that you are really doing it and not just being lucky. This is why it's good to work with cross validation instead of one train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "TE4z7B6g9Xcu"
   },
   "outputs": [],
   "source": [
    "     "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3-[Logistic Regression]-Titanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
